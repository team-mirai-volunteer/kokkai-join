#!/usr/bin/env -S deno run -A

// Standard library imports
import { load } from "jsr:@std/dotenv";

// Third-party library imports
import { Settings } from "npm:llamaindex";
import { OllamaEmbedding } from "npm:@llamaindex/ollama";
import { Pool } from "npm:pg";
import pgvector from "npm:pgvector/pg";

// Local imports
import type { SpeechResult } from "../types/kokkai.ts";
import {
  DEFAULT_OLLAMA_BASE_URL,
  DEFAULT_TOP_K_RESULTS,
  EMBEDDING_MODEL_NAME,
  MAX_DB_CONNECTIONS,
} from "../config/constants.ts";
import { QueryPlanningService } from "../services/query-planning.ts";
import { VectorSearchService } from "../services/vector-search.ts";
import { AnswerGenerationService } from "../services/answer-generation.ts";
import { RelevanceEvaluationService } from "../services/relevance-evaluation.ts";

/**
 * Main orchestrator class for the refactored Kokkai RAG CLI
 */
class RefactoredKokkaiRAGCLI {
  private dbPool: Pool | null = null;
  private queryPlanningService!: QueryPlanningService;
  private vectorSearchService!: VectorSearchService;
  private answerGenerationService!: AnswerGenerationService;
  private relevanceEvaluationService!: RelevanceEvaluationService;

  /**
   * Initialize the CLI with all required services
   */
  async initialize(): Promise<void> {
    // ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
    await load({ export: true });

    const databaseUrl = Deno.env.get("DATABASE_URL");
    const ollamaBaseUrl = Deno.env.get("OLLAMA_BASE_URL") || DEFAULT_OLLAMA_BASE_URL;
    const cerebrasApiKey = Deno.env.get("CEREBRAS_API_KEY");

    if (!databaseUrl) {
      throw new Error("DATABASE_URL environment variable is required");
    }

    if (!cerebrasApiKey) {
      throw new Error("CEREBRAS_API_KEY environment variable is required");
    }

    // OllamaåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«è¨­å®šï¼ˆåŸ‹ã‚è¾¼ã¿ã¯å¼•ãç¶šãOllamaã‚’ä½¿ç”¨ï¼‰
    try {
      Settings.embedModel = new OllamaEmbedding({
        model: EMBEDDING_MODEL_NAME,
        config: {
          host: ollamaBaseUrl,
        },
      });
      // Settings.llmã¯å‰Šé™¤ï¼ˆCerebrasã‚’ç›´æ¥ä½¿ç”¨ï¼‰
    } catch (error) {
      throw new Error(
        `Failed to initialize Ollama embedding: ${(error as Error).message}`,
      );
    }

    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«
    this.dbPool = new Pool({
      connectionString: databaseUrl,
      max: MAX_DB_CONNECTIONS,
    });

    // pgvectorã‚¿ã‚¤ãƒ—ç™»éŒ²
    const client = await this.dbPool.connect();
    try {
      await pgvector.registerTypes(client);
    } finally {
      client.release();
    }

    // ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–
    this.queryPlanningService = new QueryPlanningService();
    this.vectorSearchService = new VectorSearchService(this.dbPool);
    this.answerGenerationService = new AnswerGenerationService();
    this.relevanceEvaluationService = new RelevanceEvaluationService();

    console.log("ğŸš€ Kokkai RAG CLI with Cerebras initialized successfully");
  }

  /**
   * Perform search using query planning and vector search
   */
  async search(
    userQuery: string,
    maxResults: number = DEFAULT_TOP_K_RESULTS,
  ): Promise<SpeechResult[]> {
    // ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ã‚’ä½¿ç”¨ã—ãŸæ¤œç´¢
    const queryPlan = await this.queryPlanningService.createQueryPlan(userQuery);
    return this.vectorSearchService.executeSearchPlan(queryPlan, maxResults);
  }

  /**
   * Generate answer from search results
   */
  generateAnswer(query: string, results: SpeechResult[]): Promise<string> {
    return this.answerGenerationService.generateAnswer(query, results);
  }

  /**
   * Evaluate relevance of search results
   */
  evaluateRelevance(
    query: string,
    results: SpeechResult[],
  ): Promise<SpeechResult[]> {
    return this.relevanceEvaluationService.evaluateRelevance(query, results);
  }

  /**
   * Get database statistics
   */
  async getStats(): Promise<void> {
    if (!this.dbPool) return;

    try {
      const totalResult = await this.dbPool.query(
        'SELECT COUNT(*) as count FROM "Speech"',
      );
      const embeddedResult = await this.dbPool.query(
        "SELECT COUNT(*) as count FROM kokkai_speech_embeddings",
      );

      console.log("\nğŸ“Š Database Statistics:");
      console.log(`Total speeches: ${totalResult.rows[0].count}`);
      console.log(`Embedded speeches: ${embeddedResult.rows[0].count}`);
      const percentage = (embeddedResult.rows[0].count / totalResult.rows[0].count) * 100;
      console.log(`Embedded percentage: ${percentage.toFixed(1)}%`);
    } catch (error) {
      console.error("Failed to get stats:", error);
    }
  }

  /**
   * Close database connections and cleanup
   */
  async close(): Promise<void> {
    if (this.dbPool) {
      await this.dbPool.end();
      console.log("ğŸ“Š Database connection closed");
    }
  }
}

/**
 * Main function - CLI entry point
 */
async function main(): Promise<void> {
  const args = Deno.args;

  if (args.length === 0) {
    console.error(
      'âŒ Usage: deno run -A scripts/persistent-rag-cli-refactored.ts "æ¤œç´¢ã‚¯ã‚¨ãƒª"',
    );
    console.error(
      '   Example: deno run -A scripts/persistent-rag-cli-refactored.ts "å²¸ç”°ç·ç†ã®é˜²è¡›è²»ã«ã¤ã„ã¦"',
    );
    Deno.exit(1);
  }

  const query = args.join(" ");
  const ragCli = new RefactoredKokkaiRAGCLI();

  try {
    await ragCli.initialize();
    await ragCli.getStats();

    // ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢å®Ÿè¡Œ
    const results = await ragCli.search(query);

    if (results.length === 0) {
      console.log("âŒ No relevant speeches found.");
      return;
    }

    // é–¢é€£æ€§è©•ä¾¡ã§ãƒã‚¤ã‚ºã‚’é™¤å»
    const relevantResults = await ragCli.evaluateRelevance(query, results);

    if (relevantResults.length === 0) {
      console.log("âŒ No relevant speeches found after filtering.");
      return;
    }

    // æ¤œç´¢çµæœã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
    console.log("\nğŸ“‹ Relevant Search Results Details:");
    console.log(`Found ${relevantResults.length} relevant results\n`);

    if (relevantResults.length > 5) {
      console.log(`... and ${relevantResults.length - 5} more results\n`);
    }

    // ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±
    console.log("ğŸ“Š Data Statistics:");
    console.log(`  Total results: ${relevantResults.length}`);

    // LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆ
    console.log("\nğŸ¤– Generating AI answer...\n");
    const answer = await ragCli.generateAnswer(query, relevantResults);

    console.log("â•".repeat(80));
    console.log("\n" + answer + "\n");
    console.log("â•".repeat(80));
  } catch (error) {
    console.error("âŒ Error:", error);
    Deno.exit(1);
  } finally {
    await ragCli.close();
  }
}

if (import.meta.main) {
  await main();
}
