// Answer generation service using Chain of Agents approach

import { cerebrasClient, CEREBRAS_MODEL } from "../config/cerebras.ts";
import type { SpeechResult, SubSummaryResult } from "../types/kokkai.ts";
import {
	formatSpeechResultsForPrompt,
	createSubSummaryPrompt,
	createMidConsolidationPrompt,
	createFinalAnswerPrompt,
	createSimpleAnswerPrompt,
	getSubSummarySystemPrompt,
	getMidConsolidationSystemPrompt,
	getFinalAnswerSystemPrompt,
	getSimpleAnswerSystemPrompt,
} from "../utils/prompt.ts";
import {
	CHAIN_OF_AGENTS_CHUNK_SIZE,
	CHAIN_OF_AGENTS_MIN_RESULTS,
	MID_CONSOLIDATION_CHUNK_SIZE,
	MID_CONSOLIDATION_THRESHOLD,
	CONTENT_PREVIEW_LENGTH,
} from "../config/constants.ts";

/**
 * Service responsible for generating answers using Chain of Agents approach
 */
export class AnswerGenerationService {
	/**
	 * Generate a sub-summary for a chunk of speech results
	 */
	private async generateSubSummary(
		chunk: SpeechResult[],
		chunkIndex: number,
		query: string,
	): Promise<SubSummaryResult> {
		const context = formatSpeechResultsForPrompt(chunk);
		const userPrompt = createSubSummaryPrompt(
			query,
			context,
		);

		try {
			// Cerebras Chat APIã‚’ç›´æ¥å‘¼ã³å‡ºã—
			const completion = await cerebrasClient.chat.completions.create({
				messages: [
					{
						role: "system",
						content: getSubSummarySystemPrompt(),
					},
					{ role: "user", content: userPrompt },
				],
				model: CEREBRAS_MODEL,
				max_tokens: 500,
				temperature: 0.5,
				stream: false,
			});

      console.dir(completion, {depth: null});

			// deno-lint-ignore no-explicit-any
			const text = (completion as any).choices[0]?.message?.content;
			if (!text || text.trim() === "") {
				console.warn(
					`âš ï¸ Sub-summary ${chunkIndex + 1}: Empty response from API, using fallback`,
				);
				// ç©ºãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å ´åˆã¯ç™ºè¨€å†…å®¹ã®æŠœç²‹ã‚’ä½¿ç”¨
				const preview = chunk
					.slice(0, 2)
					.map((r) => `${r.speaker}: ${r.content.substring(0, 100)}...`)
					.join("\n");
				return {
					chunkIndex: chunkIndex + 1,
					summary: `[è¦ç´„ç”Ÿæˆå¤±æ•—] ç™ºè¨€å†…å®¹:\n${preview}`,
					sourceCount: chunk.length,
				};
			}

			return {
				chunkIndex: chunkIndex + 1,
				summary: text,
				sourceCount: chunk.length,
			};
		} catch (error) {
			console.error(`âŒ Sub-summary ${chunkIndex + 1} failed:`, error);
			// APIã‚¨ãƒ©ãƒ¼ã®å ´åˆã‚‚ç™ºè¨€å†…å®¹ã®æŠœç²‹ã‚’è¿”ã™
			const preview = chunk
				.slice(0, 2)
				.map((r) => `${r.speaker}: ${r.content.substring(0, 100)}...`)
				.join("\n");
			return {
				chunkIndex: chunkIndex + 1,
				summary: `[è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼] ç™ºè¨€å†…å®¹:\n${preview}`,
				sourceCount: chunk.length,
			};
		}
	}

	/**
	 * Generate answer using Chain of Agents multi-stage summarization
	 */
	async generateAnswer(
		query: string,
		results: SpeechResult[],
	): Promise<string> {
		console.log(`\nğŸ¤– Generating answer using Chain of Agents...`);
		console.log(`ğŸ“Š Total results to process: ${results.length}`);

		// çµæœãŒå°‘ãªã„å ´åˆã¯å¾“æ¥ã®å‡¦ç†
		if (results.length <= CHAIN_OF_AGENTS_MIN_RESULTS) {
			return this.generateSimpleAnswer(query, results);
		}

		// Chain of Agents: ç™ºè¨€è€…ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ã‹ã‚‰è¦ç´„å‡¦ç†
		// Step 0: ç™ºè¨€è€…ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆåŒä¸€ç™ºè¨€è€…ã®ç™ºè¨€ãŒæ··åœ¨ã—ãªã„ã‚ˆã†ã«ï¼‰
		const speakerGroups = new Map<string, SpeechResult[]>();
		for (const result of results) {
			const speakerKey = `${result.speaker}_${result.party}`;
			if (!speakerGroups.has(speakerKey)) {
				speakerGroups.set(speakerKey, []);
			}
			speakerGroups.get(speakerKey)!.push(result);
		}

		console.log(`ğŸ“Š Grouped into ${speakerGroups.size} speakers`);

		// å„ç™ºè¨€è€…ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ï¼ˆåŒä¸€ç™ºè¨€è€…ã®ç™ºè¨€ã‚’ã¾ã¨ã‚ã¦å‡¦ç†ï¼‰
		const chunks: SpeechResult[][] = [];
		for (const [_, speeches] of speakerGroups) {
			// ç™ºè¨€è€…ã”ã¨ã«ãƒãƒ£ãƒ³ã‚¯åŒ–
			for (let i = 0; i < speeches.length; i += CHAIN_OF_AGENTS_CHUNK_SIZE) {
				const chunk = speeches.slice(i, i + CHAIN_OF_AGENTS_CHUNK_SIZE);
				chunks.push(chunk);
			}
		}

		console.log(`ğŸ“¦ Split into ${chunks.length} chunks for processing`);

		// Step 1: å„ãƒãƒ£ãƒ³ã‚¯ã‚’ç›´åˆ—å‡¦ç†ã§ã‚µãƒ–è¦ç´„
		console.log(`âš™ï¸ Step 1: Generating sub-summaries...`);
		const subSummaries: SubSummaryResult[] = [];

		for (let chunkIndex = 0; chunkIndex < chunks.length; chunkIndex++) {
			const subSummary = await this.generateSubSummary(
				chunks[chunkIndex],
				chunkIndex,
				query,
			);
			subSummaries.push(subSummary);
			console.log(
				`  âœ“ Generated sub-summary ${chunkIndex + 1}/${chunks.length}`,
			);
		}

		console.log(`âœ… Generated ${subSummaries.length} sub-summaries`);

		// Step 2: ã‚µãƒ–è¦ç´„ãŒå¤šã„å ´åˆã¯ä¸­é–“çµ±åˆ
		let finalSummaries = subSummaries.map((s) => s.summary);
		if (subSummaries.length > MID_CONSOLIDATION_THRESHOLD) {
			console.log(`âš™ï¸ Step 2: Intermediate consolidation...`);
			const midChunkSize = MID_CONSOLIDATION_CHUNK_SIZE;
			const midSummaries: string[] = [];

			for (let i = 0; i < finalSummaries.length; i += midChunkSize) {
				const midChunk = finalSummaries.slice(i, i + midChunkSize);
				const midPrompt = createMidConsolidationPrompt(query, midChunk, i);

				try {
					// Cerebras Chat APIã‚’ç›´æ¥å‘¼ã³å‡ºã—
					const completion = await cerebrasClient.chat.completions.create({
						messages: [
							{
								role: "system",
								content: getMidConsolidationSystemPrompt(),
							},
							{ role: "user", content: midPrompt },
						],
						model: CEREBRAS_MODEL,
						max_tokens: 1000,
						temperature: 0.5,
						stream: false,
					});

					// deno-lint-ignore no-explicit-any
					const text = (completion as any).choices[0]?.message?.content;
					if (!text) {
						throw new Error("No text in completion response");
					}
          console.dir(completion, {depth: null});
					midSummaries.push(text);
				} catch (error) {
					console.error(`âŒ Mid-level consolidation failed:`, error);
					midSummaries.push(midChunk.join("\n"));
				}
			}

			finalSummaries = midSummaries;
			console.log(
				`âœ… Consolidated to ${midSummaries.length} intermediate summaries`,
			);
		}

		// Step 3: æœ€çµ‚çµ±åˆã¨å›ç­”ç”Ÿæˆ
		console.log(`âš™ï¸ Step 3: Final answer generation...`);
		const finalContext = finalSummaries
			.map((s, idx) => `ã€è¦ç´„${idx + 1}ã€‘\n${s}`)
			.join("\n\n");

		const finalPrompt = createFinalAnswerPrompt(query, finalContext);

		try {
			// Cerebras Chat APIã‚’ç›´æ¥å‘¼ã³å‡ºã—ï¼ˆæœ€çµ‚å›ç­”ã¯è©³ç´°ã«ï¼‰
			const completion = await cerebrasClient.chat.completions.create({
				messages: [
					{
						role: "system",
						content: getFinalAnswerSystemPrompt(),
					},
					{ role: "user", content: finalPrompt },
				],
				model: CEREBRAS_MODEL,
				max_tokens: 3000,
				temperature: 0.7,
				stream: false,
			});

			// deno-lint-ignore no-explicit-any
			const text = (completion as any).choices[0]?.message?.content;
			if (!text) {
				throw new Error("No text in completion response");
			}

			console.log(`âœ… Final answer generated successfully`);
			return text;
		} catch (error) {
			console.error("âŒ Final answer generation error:", error);
			return this.generateSimpleAnswer(query, results);
		}
	}

	/**
	 * Generate simple answer (fallback method)
	 */
	async generateSimpleAnswer(
		query: string,
		results: SpeechResult[],
	): Promise<string> {
		const context = formatSpeechResultsForPrompt(results);
		const prompt = createSimpleAnswerPrompt(query, context);

		try {
			// Cerebras Chat APIã‚’ç›´æ¥å‘¼ã³å‡ºã—
			const completion = await cerebrasClient.chat.completions.create({
				messages: [
					{ role: "system", content: getSimpleAnswerSystemPrompt() },
					{ role: "user", content: prompt },
				],
				model: CEREBRAS_MODEL,
				max_tokens: 2000,
				temperature: 0.7,
				stream: false,
			});

			// deno-lint-ignore no-explicit-any
			const text = (completion as any).choices[0]?.message?.content;
			if (!text) {
				throw new Error("No text in completion response");
			}
			return text;
		} catch (error) {
			console.error("âŒ LLM generation error:", error);
			return `æ¤œç´¢çµæœã«åŸºã¥ãæƒ…å ±:

${results
	.map(
		(result, index) =>
			`${index + 1}. ${result.speaker} (${result.party})
   æ—¥ä»˜: ${result.date}
   ä¼šè­°: ${result.meeting}
   å†…å®¹: ${result.content.substring(0, CONTENT_PREVIEW_LENGTH)}...
   å‡ºå…¸: ${result.url}
   é–¢é€£åº¦: ${result.score.toFixed(3)}`,
	)
	.join("\n\n")}`;
		}
	}
}
