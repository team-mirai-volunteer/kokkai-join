// Query planning service for Kokkai RAG system

import { getOpenAIClient } from "../config/openai.js";
import type { QueryPlan } from "../types/kokkai.js";
import { getQueryPlanSystemPrompt } from "../utils/prompt.js";

/**
 * ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã€‚
 *
 * - å½¹å‰²: ãƒ¦ãƒ¼ã‚¶è³ªå•ã‚’è§£æã—ã€æ¤œç´¢ã«é©ã—ãŸã‚µãƒ–ã‚¯ã‚¨ãƒªã‚„ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼ˆè©±è€…/æ”¿å…š/æœŸé–“ãªã©ï¼‰ã‚’æŠ½å‡ºã€‚
 * - æœ¬å®Ÿè£…: OpenAI çµŒç”±ã§é¸æŠã—ãŸ LLM ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã—ã¦ JSON å½¢å¼ã®ãƒ—ãƒ©ãƒ³ã‚’ç”Ÿæˆã™ã‚‹ã€‚
 */
interface RawPlanData {
  subqueries?: string[];
  entities?: {
    speakers?: string[];
    parties?: string[];
    topics?: string[];
    meetings?: string[];
    positions?: string[];
    dateRange?: {
      start?: string;
      end?: string;
    };
  };
  enabledStrategies?: string[];
  confidence?: number;
  estimatedComplexity?: number;
}

export class QueryPlanningService {
  /** ãƒ¦ãƒ¼ã‚¶è³ªå•ã‹ã‚‰ã‚¯ã‚¨ãƒªãƒ—ãƒ©ãƒ³ï¼ˆã‚µãƒ–ã‚¯ã‚¨ãƒªç­‰ï¼‰ã‚’ç”Ÿæˆ */
  async createQueryPlan(userQuestion: string): Promise<QueryPlan> {
    console.log("ğŸ§  Planning query strategy...");

    const userPrompt = `è³ªå•: "${userQuestion}"`;

    let planText: string | undefined;
    try {
      const client = getOpenAIClient();
      const completion = await client.chat.completions.create({
        messages: [
          { role: "system", content: getQueryPlanSystemPrompt() },
          { role: "user", content: userPrompt },
        ],
        model: "openai/gpt-4o-mini",
        max_tokens: 3000,
        temperature: 0.3, // è¨ˆç”»ç”Ÿæˆã¯ç¢ºå®šçš„ã«
        stream: false,
      });

      planText = completion.choices[0]?.message?.content?.trim();
      if (!planText) {
        throw new Error("No text in completion response");
      }
    } catch (error) {
      console.error("âŒ Planning error:", error);
      throw error;
    }

    // JSONãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
    let planData: RawPlanData;
    try {
      planData = JSON.parse(planText) as RawPlanData;
    } catch (parseError) {
      throw new Error(
        `Failed to parse LLM response as JSON: ${
          (parseError as Error).message
        }\nResponse: ${planText}`,
      );
    }

    // QueryPlanå½¢å¼ã«å¤‰æ›
    const rawDateRange = planData.entities?.dateRange;
    const normalizedDateRange =
      rawDateRange &&
      typeof rawDateRange.start === "string" &&
      typeof rawDateRange.end === "string"
        ? {
            start: rawDateRange.start,
            end: rawDateRange.end,
          }
        : undefined;

    const plan: QueryPlan = {
      originalQuestion: userQuestion,
      subqueries: planData.subqueries || [userQuestion],
      entities: {
        speakers: planData.entities?.speakers || [],
        parties: planData.entities?.parties || [],
        topics: planData.entities?.topics || [],
        meetings: planData.entities?.meetings || [],
        positions: planData.entities?.positions || [],
        dateRange: normalizedDateRange,
      },
      enabledStrategies: planData.enabledStrategies || ["vector"],
      confidence: planData.confidence || 0.5,
      estimatedComplexity: planData.estimatedComplexity || 2,
    };

    return plan;
  }
}
